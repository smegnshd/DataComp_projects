{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2290642f",
   "metadata": {},
   "source": [
    "# Exploring your working directory\n",
    "In order to import data into Python, you should first have an idea of what files are in your working directory.\n",
    "\n",
    "IPython, which is running on DataCamp's servers, has a bunch of cool commands, including its magic commands. For example, starting a line with ! gives you complete system shell access. This means that the IPython magic command ! ls will display the contents of your current directory. Your task is to use the IPython magic command ! ls to check out the contents of your current directory and answer the following question: which of the following files is in your working directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea2f099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Possible Answers\\n\\nhuck_finn.txt\\n\\ntitanic.csv\\n\\nmoby_dick.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Possible Answers\n",
    "\n",
    "huck_finn.txt\n",
    "\n",
    "titanic.csv\n",
    "\n",
    "moby_dick.txt\"\"\"\n",
    "\n",
    "#Answer= moby_dick.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be572db",
   "metadata": {},
   "source": [
    "# Importing entire text files\n",
    "In this exercise, you'll be working with the file moby_dick.txt. It is a text file that contains the opening sentences of Moby Dick, one of the great American novels! Here you'll get experience opening a text file, printing its contents to the shell and, finally, closing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file: file\n",
    "file = open('moby_dick.txt' ,mode= 'r') # mode = 'r' for read only\n",
    "\n",
    "# Print it\n",
    "print(file.read()) \n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)\n",
    "\n",
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f963f55",
   "metadata": {},
   "source": [
    "# Importing text files line by line\n",
    "For large files, we may not want to print all of their content to the shell: you may wish to print only the first few lines. Enter the readline() method, which allows you to do this. When a file called file is open, you can print out the first line by executing file.readline(). If you execute the same command again, the second line will print, and so on.\n",
    "\n",
    "In the introductory video, Hugo also introduced the concept of a context manager. He showed that you can bind a variable file by using a context manager construct:\n",
    "\n",
    "with open('huck_finn.txt') as file:\n",
    "While still within this construct, the variable file will be bound to open('huck_finn.txt'); thus, to print the file to the shell, all the code you need to execute is:\n",
    "\n",
    "with open('huck_finn.txt') as file:\n",
    "    print(file.readline())\n",
    "You'll now use these tools to print the first few lines of moby_dick.txt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c753bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Open moby_dick.txt using the with context manager and the variable file.\n",
    "Print the first three lines of the file to the shell by using readline() three times within \n",
    "the context manager.\n",
    "\"\"\"\n",
    "# Read & print the first 3 lines\n",
    "with open('moby_dick.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836dacd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pop quiz: examples of flat files\\nYou're now well-versed in importing text files and you're about to become a wiz at importing flat files. But can you remember exactly what a flat file is? Test your knowledge by answering the following question: which of these file types below is NOT an example of a flat file?\\n\\nAnswer the question\\n50XP\\nPossible Answers\\n\\nA .csv file.\\n\\nA tab-delimited .txt.\\n\\nA relational database (e.g. PostgreSQL).\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Pop quiz: examples of flat files\n",
    "You're now well-versed in importing text files and you're about to become a wiz at importing flat files. But can you remember exactly what a flat file is? Test your knowledge by answering the following question: which of these file types below is NOT an example of a flat file?\n",
    "\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "A .csv file.\n",
    "\n",
    "A tab-delimited .txt.\n",
    "\n",
    "A relational database (e.g. PostgreSQL).\"\"\"\n",
    "#answer= relational database (e.g. PostgreSQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54021192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pop quiz: what exactly are flat files?\\nWhich of the following statements about flat files is incorrect?\\n\\nAnswer the question\\n50XP\\nPossible Answers\\n\\nFlat files consist of rows and each row is called a record.\\n\\nFlat files consist of multiple tables with structured relationships between the tables.\\n\\nA record in a flat file is composed of fields or attributes, each of which contains at most one item of information.\\n\\nFlat files are pervasive in data science.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Pop quiz: what exactly are flat files?\n",
    "Which of the following statements about flat files is incorrect?\n",
    "\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "Flat files consist of rows and each row is called a record.\n",
    "\n",
    "Flat files consist of multiple tables with structured relationships between the tables.\n",
    "\n",
    "A record in a flat file is composed of fields or attributes, each of which contains at most one item of information.\n",
    "\n",
    "Flat files are pervasive in data science.\"\"\"\n",
    "#answer=Flat files consist of multiple tables with structured relationships \n",
    "#between the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aafa5b9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why we like flat files and the Zen of Python\\nIn PythonLand, there are currently hundreds of Python Enhancement Proposals, commonly referred to as PEPs. PEP8, for example, is a standard style guide for Python, written by our sensei Guido van Rossum himself. It is the basis for how we here at DataCamp ask our instructors to style their code. Another one of my favorites is PEP20, commonly called the Zen of Python. Its abstract is as follows:\\n\\nLong time Pythoneer Tim Peters succinctly channels the BDFL's guiding principles for Python's design into 20 aphorisms, only 19 of which have been written down.\\n\\nIf you don't know what the acronym BDFL stands for, I suggest that you look here. You can print the Zen of Python in your shell by typing import this into it! You're going to do this now and the 5th aphorism (line) will say something of particular interest.\\n\\nThe question you need to answer is: what is the 5th aphorism of the Zen of Python?\\n\\nInstructions\\n50 XP\\nPossible Answers\\n\\nFlat is better than nested.\\n\\nFlat files are essential for data science.\\n\\nThe world is representable as a flat file.\\n\\nFlatness is in the eye of the beholder.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Why we like flat files and the Zen of Python\n",
    "In PythonLand, there are currently hundreds of Python Enhancement Proposals, commonly referred to as PEPs. PEP8, for example, is a standard style guide for Python, written by our sensei Guido van Rossum himself. It is the basis for how we here at DataCamp ask our instructors to style their code. Another one of my favorites is PEP20, commonly called the Zen of Python. Its abstract is as follows:\n",
    "\n",
    "Long time Pythoneer Tim Peters succinctly channels the BDFL's guiding principles for Python's design into 20 aphorisms, only 19 of which have been written down.\n",
    "\n",
    "If you don't know what the acronym BDFL stands for, I suggest that you look here. You can print the Zen of Python in your shell by typing import this into it! You're going to do this now and the 5th aphorism (line) will say something of particular interest.\n",
    "\n",
    "The question you need to answer is: what is the 5th aphorism of the Zen of Python?\n",
    "\n",
    "Instructions\n",
    "50 XP\n",
    "Possible Answers\n",
    "\n",
    "Flat is better than nested.\n",
    "\n",
    "Flat files are essential for data science.\n",
    "\n",
    "The world is representable as a flat file.\n",
    "\n",
    "Flatness is in the eye of the beholder.\"\"\"\n",
    "#answer=Flat is better than nested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13b364",
   "metadata": {},
   "source": [
    "# Using NumPy to import flat files\n",
    "In this exercise, you're now going to load the MNIST digit recognition dataset using the numpy function loadtxt() and see just how easy it can be:\n",
    "\n",
    "The first argument will be the filename.\n",
    "The second will be the delimiter which, in this case, is a comma.\n",
    "You can find more information about the MNIST dataset here on the webpage of Yann LeCun, who is currently Director of AI Research at Facebook and Founding Director of the NYU Center for Data Science, among many other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import numpy as np\n",
    "\n",
    "# Assign filename to variable: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Load file as array: digits\n",
    "digits = np.loadtxt(file, delimiter=',')\n",
    "\n",
    "# Print datatype of digits\n",
    "print(type(digits))\n",
    "\n",
    "# Select and reshape a row\n",
    "im = digits[21, 1:]\n",
    "im_sq = np.reshape(im, (28, 28))\n",
    "\n",
    "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a7947",
   "metadata": {},
   "source": [
    "# Customizing your NumPy import\n",
    "What if there are rows, such as a header, that you don't want to import? What if your file has a delimiter other than a comma? What if you only wish to import particular columns?\n",
    "\n",
    "There are a number of arguments that np.loadtxt() takes that you'll find useful:\n",
    "\n",
    "delimiter changes the delimiter that loadtxt() is expecting.\n",
    "- You can use ',' for comma-delimited.\n",
    "- You can use '\\t' for tab-delimited.\n",
    "- skiprows allows you to specify how many rows (not indices) you wish to skip\n",
    "usecols takes a list of the indices of the columns you wish to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c803e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'digits_header.txt'\n",
    "\n",
    "# Load the data: data\n",
    "data = np.loadtxt(file, delimiter='\\t', skiprows=1 , usecols={0,2})\n",
    "\n",
    "# Print data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3985961",
   "metadata": {},
   "source": [
    "# Importing different datatypes\n",
    "The file seaslug.txt\n",
    "\n",
    "- has a text header, consisting of strings\n",
    "- is tab-delimited.\n",
    "These data consists of percentage of sea slug larvae that had metamorphosed in a given time period. \n",
    "Read more here.\n",
    "\n",
    "Due to the header, if you tried to import it as-is using np.loadtxt(), Python would throw you a ValueError and tell you that it could not convert string to float. There are two ways to deal with this: firstly, you can set the data type argument dtype equal to str (for string).\n",
    "\n",
    "Alternatively, you can skip the first row as we have seen before, using the skiprows argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'seaslug.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
    "\n",
    "# Print the first element of data\n",
    "print(data[0])\n",
    "\n",
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = np.loadtxt(file, delimiter='\\t', dtype=float, skiprows=1)\n",
    "\n",
    "# Print the 10th element of data_float\n",
    "print(data_float[9])\n",
    "\n",
    "# Plot a scatterplot of the data\n",
    "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('percentage of larvae')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1383c",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes (1)\n",
    "Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function np.loadtxt() will freak at this. There is another function, np.genfromtxt(), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be.\n",
    "\n",
    "Import 'titanic.csv' using the function np.genfromtxt() as follows:\n",
    "\n",
    "data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. You can test this by checking out the array's shape in the shell by executing np.shape(data).\n",
    "\n",
    "Accessing rows and columns of structured arrays is super-intuitive: to get the ith row, merely execute data[i] and to get the column with name 'Fare', execute data['Fare'].\n",
    "\n",
    "After importing the Titanic data as a structured array (as per the instructions above), print the entire column with the name Survived to the shell. What are the last 4 values of this column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d778a2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Possible Answers\\n1,0,0,1.\\n1,2,0,0.\\n1,0,1,0.\\n0,1,1,1.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Possible Answers\n",
    "1,0,0,1.\n",
    "1,2,0,0.\n",
    "1,0,1,0.\n",
    "0,1,1,1.\n",
    "\"\"\"\n",
    "#answer=1010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70562ba2",
   "metadata": {},
   "source": [
    "# Working with mixed datatypes (2)\n",
    "You have just used np.genfromtxt() to import data containing mixed datatypes. There is also another function np.recfromcsv() that behaves similarly to np.genfromtxt(), except that its default dtype is None. In this exercise, you'll practice using this to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd745467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the filename: file\n",
    "file = 'titanic.csv'\n",
    "\n",
    "# Import file using np.recfromcsv: d\n",
    "d= np.recfromcsv(file, delimiter = ',', names=True, dtype=None)\n",
    "\n",
    "# Print out first three entries of d\n",
    "print(d[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b6066",
   "metadata": {},
   "source": [
    "# Using pandas to import flat files as DataFrames (1)\n",
    "In the last exercise, you were able to import flat files containing columns with different datatypes as numpy arrays. However, the DataFrame object in pandas is a more appropriate structure in which to store such data and, thankfully, we can easily import files of mixed data types as DataFrames using the pandas functions read_csv() and read_table()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'titanic.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# View the head of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645031d",
   "metadata": {},
   "source": [
    "# Using pandas to import flat files as DataFrames (2)\n",
    "In the last exercise, you were able to import flat files into a pandas DataFrame. As a bonus, it is then straightforward to retrieve the corresponding numpy array using the attribute values. You'll now have a chance to do this using the MNIST dataset, which is available as digits.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72adeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the filename: file\n",
    "file = 'digits.csv'\n",
    "\n",
    "# Read the first 5 rows of the file into a DataFrame: data\n",
    "data = pd.read_csv(file, nrows=5 , header= None)\n",
    "\n",
    "# Build a numpy array from the DataFrame: data_array\n",
    "data_array = np.array(data)\n",
    "\n",
    "# Print the datatype of data_array to the shell\n",
    "print(type(data_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebee65",
   "metadata": {},
   "source": [
    "# Customizing your pandas import\n",
    "The pandas package is also great at dealing with many of the issues you will encounter when importing data as a data scientist, such as comments occurring in flat files, empty lines and missing values. Note that missing values are also commonly referred to as NA or NaN. To wrap up this chapter, you're now going to import a slightly corrupted copy of the Titanic dataset titanic_corrupt.txt, which\n",
    "\n",
    "- contains comments after the character '#'\n",
    "- is tab-delimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'titanic_corrupt.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file, sep='\\t' , comment='#', na_values='Nothing')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Plot 'Age' variable in a histogram\n",
    "pd.DataFrame.hist(data[['Age']])\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369bf7a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
