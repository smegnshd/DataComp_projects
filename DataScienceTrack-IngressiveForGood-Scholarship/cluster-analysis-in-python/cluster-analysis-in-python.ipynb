{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c43159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupervised learning in real world\n",
    "# Which of the following examples can be solved with unsupervised learning?\n",
    "\n",
    "# Answer the question\n",
    "# 50 XP\n",
    "# Possible Answers\n",
    "# A list of tweets to be classified based on their sentiment, the data has tweets associated with a positive or negative sentiment.\n",
    "\n",
    "# A spam recognition system that marks incoming emails as spam, the data has emails marked as spam and not spam.\n",
    "\n",
    "# Segmentation of learners at DataCamp based on courses they complete. The training data has no labels.\n",
    "\n",
    "\"\"\"ANSWER\"\"\"\n",
    "\"\"\"PRESS 3\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b27ee",
   "metadata": {},
   "source": [
    "# Pokémon sightings\n",
    "There have been reports of sightings of rare, legendary Pokémon. You have been asked to investigate! Plot the coordinates of sightings to find out where the Pokémon might be. The X and Y coordinates of the points are stored in list x and y, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f943b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting class from matplotlib library\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y)\n",
    "\n",
    "# Display the scatter plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf7fb0",
   "metadata": {},
   "source": [
    "# Pokémon sightings: hierarchical clustering\n",
    "We are going to continue the investigation into the sightings of legendary Pokémon from the previous exercise. Remember that in the scatter plot of the previous exercise, you identified two areas where Pokémon sightings were dense. This means that the points seem to separate into two clusters. In this exercise, you will form two clusters of the sightings using hierarchical clustering.\n",
    "\n",
    "'x' and 'y' are columns of X and Y coordinates of the locations of sightings, stored in a Pandas data frame, df. The following are available for use: matplotlib.pyplot as plt, seaborn as sns, and pandas as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64573a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linkage and fcluster functions\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Use the linkage() function to compute distances\n",
    "Z = linkage(df, 'ward')\n",
    "\n",
    "# Generate cluster labels\n",
    "df['cluster_labels'] = fcluster(Z, 2, criterion='maxclust')\n",
    "\n",
    "# Plot the points with seaborn\n",
    "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec7210",
   "metadata": {},
   "source": [
    "# Pokémon sightings: k-means clustering\n",
    "We are going to continue the investigation into the sightings of legendary Pokémon from the previous exercise. Just like the previous exercise, we will use the same example of Pokémon sightings. In this exercise, you will form clusters of the sightings using k-means clustering.\n",
    "\n",
    "x and y are columns of X and Y coordinates of the locations of sightings, stored in a Pandas data frame, df. The following are available for use: matplotlib.pyplot as plt, seaborn as sns, and pandas as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c156367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import kmeans and vq functions\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# Compute cluster centers\n",
    "centroids,_ = kmeans(df, 2)\n",
    "\n",
    "# Assign cluster labels\n",
    "df['cluster_labels'], _ = vq(df, centroids)\n",
    "\n",
    "# Plot the points with seaborn\n",
    "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c948f",
   "metadata": {},
   "source": [
    "# Normalize basic list data\n",
    "Now that you are aware of normalization, let us try to normalize some data. goals_for is a list of goals scored by a football team in their last ten matches. Let us standardize the data using the whiten() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24512723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import the whiten function.\n",
    "Use the whiten() function to standardize the data.\"\"\"\n",
    "# Import the whiten function\n",
    "from scipy.cluster.vq import whiten\n",
    "\n",
    "goals_for = [4,3,2,3,1,1,2,0,1,4]\n",
    "\n",
    "# Use the whiten() function to standardize the data\n",
    "scaled_data = whiten(goals_for)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59566abb",
   "metadata": {},
   "source": [
    "# Visualize normalized data\n",
    "After normalizing your data, you can compare the scaled data to the original data to see the difference. The variables from the last exercise, goals_for and scaled_data are already available to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot original data\n",
    "plt.plot(goals_for, label='original')\n",
    "\n",
    "# Plot scaled data\n",
    "plt.plot(scaled_data, label='scaled')\n",
    "\n",
    "# Show the legend in the plot\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396be0c",
   "metadata": {},
   "source": [
    "# Normalization of small numbers\n",
    "In earlier examples, you have normalization of whole numbers. In this exercise, you will look at the treatment of fractional numbers - the change of interest rates in the country of Bangalla over the years. For your use, matplotlib.pyplot is imported as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f212b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "rate_cuts = [0.0025, 0.001, -0.0005, -0.001, -0.0005, 0.0025, -0.001, -0.0015, -0.001, 0.0005]\n",
    "\n",
    "# Use the whiten() function to standardize the data\n",
    "scaled_data = whiten(rate_cuts)\n",
    "\n",
    "# Plot original data\n",
    "plt.plot(rate_cuts, label='original')\n",
    "\n",
    "# Plot scaled data\n",
    "plt.plot(scaled_data, label='scaled')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be1b7c",
   "metadata": {},
   "source": [
    "# FIFA 18: Normalize data\n",
    "FIFA 18 is a football video game that was released in 2017 for PC and consoles. The dataset that you are about to work on contains data on the 1000 top individual players in the game. You will explore various features of the data as we move ahead in the course. In this exercise, you will work with two columns, eur_wage, the wage of a player in Euros and eur_value, their current transfer market value.\n",
    "\n",
    "The data for this exercise is stored in a Pandas dataframe, fifa. whiten from scipy.cluster.vq and matplotlib.pyplot as plt have been pre-loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale wage and value\n",
    "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
    "fifa['scaled_value'] = whiten(fifa['eur_value'])\n",
    "\n",
    "\"\"\"Plot the scaled wages and transfer values of players using the .plot() method of Pandas.\"\"\"\n",
    "# Scale wage and value\n",
    "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
    "fifa['scaled_value'] = whiten(fifa['eur_value'])\n",
    "\n",
    "# Plot the two columns in a scatter plot\n",
    "fifa.plot(x='scaled_wage', y='scaled_value', kind='scatter')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"Check the mean and standard deviation of the scaled data using the .describe() method of Pandas.\n",
    "\"\"\"\n",
    "# Scale wage and value\n",
    "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
    "fifa['scaled_value'] = whiten(fifa['eur_value'])\n",
    "\n",
    "# Plot the two columns in a scatter plot\n",
    "fifa.plot(x='scaled_wage', y='scaled_value', kind = 'scatter')\n",
    "plt.show()\n",
    "\n",
    "# Check mean and standard deviation of scaled values\n",
    "print(fifa[['scaled_wage', 'scaled_value']].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf270911",
   "metadata": {},
   "source": [
    "# Hierarchical clustering: ward method\n",
    "It is time for Comic-Con! Comic-Con is an annual comic-based convention held in major cities in the world. You have the data of last year's footfall, the number of people at the convention ground at a given time. You would like to decide the location of your stall to maximize sales. Using the ward method, apply hierarchical clustering to find the two points of attraction in the area.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method = 'ward', metric = 'euclidean')\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190606e6",
   "metadata": {},
   "source": [
    "# Hierarchical clustering: single method\n",
    "Let us use the same footfall dataset and check if any changes are seen if we use a different method for clustering.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca91d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method = 'single', metric = 'euclidean')\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9c6d45",
   "metadata": {},
   "source": [
    "# Hierarchical clustering: complete method\n",
    "For the third and final time, let us use the same footfall dataset and check if any changes are seen if we use a different method for clustering.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcae576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fcluster and linkage functions\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "# Use the linkage() function\n",
    "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method = 'complete', metric = 'euclidean')\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493cc9b",
   "metadata": {},
   "source": [
    "# Visualize clusters with matplotlib\n",
    "We have discussed that visualizations are necessary to assess the clusters that are formed and spot trends in your data. Let us now focus on visualizing the footfall dataset from Comic-Con using the matplotlib module.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. cluster_labels has the cluster labels. A linkage object is stored in the variable distance_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyplot class\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define a colors dictionary for clusters\n",
    "colors = {1:'red', 2:'blue'}\n",
    "\n",
    "# Plot a scatter plot\n",
    "comic_con.plot.scatter(x = 'x_scaled', \n",
    "                \t   y = 'y_scaled',\n",
    "                       c = comic_con['cluster_labels'].apply(lambda x: colors[x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c1281",
   "metadata": {},
   "source": [
    "# Visualize clusters with seaborn\n",
    "Let us now visualize the footfall dataset from Comic Con using the seaborn module. Visualizing clusters using seaborn is easier with the inbuild hue function for cluster labels.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. cluster_labels has the cluster labels. A linkage object is stored in the variable distance_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a550bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the seaborn module\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot a scatter plot using seaborn\n",
    "sns.scatterplot(x='x_scaled', \n",
    "                y='y_scaled', \n",
    "                hue='cluster_labels', \n",
    "                data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34bcd72",
   "metadata": {},
   "source": [
    "# Create a dendrogram\n",
    "Dendrograms are branching diagrams that show the merging of clusters as we move through the distance matrix. Let us use the Comic Con footfall data to create a dendrogram.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. cluster_labels has the cluster labels. A linkage object is stored in the variable distance_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db414baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dendrogram function\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# Create a dendrogram\n",
    "dn = dendrogram(distance_matrix)\n",
    "\n",
    "# Display the dendogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many clusters in comic con data?\n",
    "# Given the dendrogram from the last exercise, how many clusters can you see in the data?\n",
    "\n",
    "# A dendrogram is stored in the variable dn. Use plt.show() to display the dendrogram.\n",
    "\n",
    "# Instructions\n",
    "# 50 XP\n",
    "# Possible Answers\n",
    "# 2 clusters\n",
    "# 3 clusters\n",
    "# 4 clusters\n",
    "\n",
    "\n",
    "\"\"\"Answers\n",
    "2 clusters\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da420ccc",
   "metadata": {},
   "source": [
    "# Timing run of hierarchical clustering\n",
    "In earlier exercises of this chapter, you have used the data of Comic-Con footfall to create clusters. In this exercise you will time how long it takes to run the algorithm on DataCamp's system.\n",
    "\n",
    "Remember that you can time the execution of small code snippets with:\n",
    "\n",
    "%timeit sum([1, 3, 2])\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. The timeit module and linkage function are already imported\n",
    "\n",
    "How long does it take to the run the linkage function on the comic con data?\n",
    "\"\"\"\n",
    " Possible Answers\n",
    "- 1-5 microseconds\n",
    "- 1-5 milliseconds\n",
    "- 1-5 seconds\n",
    "\n",
    "\"\"\"Answers\n",
    "1-5 milliseconds\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc7b22",
   "metadata": {},
   "source": [
    "# FIFA 18: exploring defenders\n",
    "In the FIFA 18 dataset, various attributes of players are present. Two such attributes are:\n",
    "\n",
    "sliding tackle: a number between 0-99 which signifies how accurate a player is able to perform sliding tackles\n",
    "aggression: a number between 0-99 which signifies the commitment and will of a player\n",
    "These are typically high in defense-minded players. In this exercise, you will perform clustering based on these attributes in the data.\n",
    "\n",
    "This data consists of 5000 rows, and is considerably larger than earlier datasets. Running hierarchical clustering on this data can take up to 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fit the scaled data in columns scaled_sliding_tackle and scaled_aggression into a hierarchical clustering algorithm. Additionally, you may want to check how long it takes to run the data in the console using the timeit module.\"\"\"\n",
    "# Fit the data into a hierarchical clustering algorithm\n",
    "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
    "\n",
    "\n",
    "\"\"\"Assign cluster labels to each row in the data using the fcluster() function (use 3 clusters).\"\"\"\n",
    "# Fit the data into a hierarchical clustering algorithm\n",
    "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
    "\n",
    "# Assign cluster labels to each row of data\n",
    "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')\n",
    "\n",
    "\n",
    "\"\"\"Display cluster centers of each cluster with respect to the scaled columns by calculating the mean value for each cluster.\"\"\"\n",
    "# Fit the data into a hierarchical clustering algorithm\n",
    "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
    "\n",
    "# Assign cluster labels to each row of data\n",
    "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')\n",
    "\n",
    "# Display cluster centers of each cluster\n",
    "print(fifa[['scaled_sliding_tackle', 'scaled_aggression', 'cluster_labels']].groupby('cluster_labels').mean())\n",
    "\n",
    "\"\"\"Create a scatter plot using seaborn with the scaled sliding tackle attribute on the x-axis and the scaled aggression attribute on the y-axis. Assign a different color to each cluster.\"\"\"\n",
    "# Fit the data into a hierarchical clustering algorithm\n",
    "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
    "\n",
    "# Assign cluster labels to each row of data\n",
    "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')\n",
    "\n",
    "# Display cluster centers of each cluster\n",
    "print(fifa[['scaled_sliding_tackle', 'scaled_aggression', 'cluster_labels']].groupby('cluster_labels').mean())\n",
    "\n",
    "# Create a scatter plot through seaborn\n",
    "sns.scatterplot(x='scaled_sliding_tackle', y='scaled_aggression', hue='cluster_labels', data=fifa)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b00b9",
   "metadata": {},
   "source": [
    "# K-means clustering: first exercise\n",
    "This exercise will familiarize you with the usage of k-means clustering on a dataset. Let us use the Comic Con dataset and check how k-means clustering works on it.\n",
    "\n",
    "Recall the two steps of k-means clustering:\n",
    "\n",
    "- Define cluster centers through kmeans() function. It has two required arguments: observations and number of clusters.\n",
    "- Assign cluster labels through the vq() function. It has two required arguments: observations and cluster centers.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kmeans and vq functions\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# Generate cluster centers\n",
    "cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
    "\n",
    "# Assign cluster labels\n",
    "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)\n",
    "\n",
    "# Plot clusters\n",
    "sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                hue='cluster_labels', data = comic_con)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fab222",
   "metadata": {},
   "source": [
    "# Runtime of k-means clustering\n",
    "Recall that it took a significantly long time to run hierarchical clustering. How long does it take to run the kmeans() function on the FIFA dataset?\n",
    "\n",
    "The data is stored in a Pandas data frame, fifa. scaled_sliding_tackle and scaled_aggression are the relevant scaled columns. timeit and kmeans have been imported.\n",
    "\n",
    "Cluster centers are defined through the kmeans() function. It has two required arguments: observations and number of clusters. You can use %timeit before a piece of code to check how long it takes to run. You can time the kmeans() function for three clusters on the fifa dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible Answers\n",
    "# ~ 50 μs (microseconds)\n",
    "# ~ 50 ms (milliseconds)\n",
    "# ~ 50 s (seconds)\n",
    "\n",
    "\"\"\"Answers\n",
    " ~ 50 ms (milliseconds)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c22692f",
   "metadata": {},
   "source": [
    "# Elbow method on distinct clusters\n",
    "Let us use the comic con data set to see how the elbow plot looks on a data set with distinct, well-defined clusters. You may want to display the data points before proceeding with the exercise.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50585cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(1, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists - num_clusters, distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "# Creat a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"==================MCQ====================\"\"\"\n",
    "# Question\n",
    "# From the elbow plot, how many clusters are there in the data?\n",
    "\n",
    "# Possible Answers\n",
    "# 2 clusters\n",
    "# 4 clusters\n",
    "# 6 clusters\n",
    "\n",
    "\"\"\"Answers\n",
    " 2 clusters\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf951e5",
   "metadata": {},
   "source": [
    "# Elbow method on uniform data\n",
    "In the earlier exercise, you constructed an elbow plot on data with well-defined clusters. Let us now see how the elbow plot looks on a data set with uniformly distributed points. You may want to display the data points on the console before proceeding with the exercise.\n",
    "\n",
    "The data is stored in a Pandas data frame, uniform_data. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "num_clusters = range(2, 7)\n",
    "\n",
    "# Create a list of distortions from the kmeans function\n",
    "for i in num_clusters:\n",
    "    cluster_centers, distortion = kmeans(uniform_data[['x_scaled', 'y_scaled']], i)\n",
    "    distortions.append(distortion)\n",
    "\n",
    "# Create a data frame with two lists - number of clusters and distortions\n",
    "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "# Creat a line plot of num_clusters and distortions\n",
    "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "plt.xticks(num_clusters)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"==================MCQ====================\"\"\"\n",
    "# Question\n",
    "# From the elbow plot, how many clusters are there in the data?\n",
    "\n",
    "# Possible Answers\n",
    "# Can not be determined\n",
    "# 3 clusters\n",
    "# 4 clusters\n",
    "\n",
    "\"\"\"Answers\n",
    " Can not be determined\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace5a84",
   "metadata": {},
   "source": [
    "# Impact of seeds on distinct clusters\n",
    "You noticed the impact of seeds on a dataset that did not have well-defined groups of clusters. In this exercise, you will explore whether seeds impact the clusters in the Comic Con data, where the clusters are well-defined.\n",
    "\n",
    "The data is stored in a Pandas data frame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d7e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
